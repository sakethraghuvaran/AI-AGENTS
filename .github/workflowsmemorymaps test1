# --- Installation Instructions ---
# Before running this script for the first time, you need to install the required libraries.
# Open your terminal or command prompt and run the following commands one by one:
#
# 1. pip install spacy
# 2. pip install networkx
# 3. pip install matplotlib
# 4. python -m spacy download en_core_web_sm
#
# After running these commands, you can execute this Python script.
# --------------------------------------------------------------------

try:
    import spacy
    from spacy.lang.en.stop_words import STOP_WORDS
    from string import punctuation
    from collections import Counter
    from heapq import nlargest
    import networkx as nx
    import matplotlib.pyplot as plt
    import random
except ModuleNotFoundError as e:
    print(f"--- ERROR: A required library is missing ---")
    print(f"Details: {e}")
    print("\nIt looks like one of the libraries needed to run this script is not installed.")
    print("Please install them by running these commands in your terminal:")
    print("\n  pip install spacy")
    print("  pip install networkx")
    print("  pip install matplotlib\n")
    print("After installing the libraries, you also need to download the language model:")
    print("  python -m spacy download en_core_web_sm\n")
    exit()

# --- Main Code ---

def load_spacy_model():
    """Loads the spaCy model and handles errors if it's not downloaded."""
    try:
        # Attempt to load the small English model
        return spacy.load("en_core_web_sm")
    except OSError:
        # This error occurs if the model is installed but not downloaded
        print("--- ERROR: spaCy language model not found ---")
        print("The 'en_core_web_sm' model is missing.")
        print("Please download it by running this command in your terminal:")
        print("\n  python -m spacy download en_core_web_sm\n")
        return None

def generate_memory_map(text, num_keywords=10, num_sentences=5):
    """
    Analyzes text to generate and display a memory map graph.

    Args:
        text (str): The input text to generate the memory map from.
        num_keywords (int): The number of keywords to extract for the map.
        num_sentences (int): The number of sentences for the summary node.
    """
    nlp = load_spacy_model()
    if nlp is None:
        return # Stop execution if the model failed to load

    # Process the entire text with spaCy
    doc = nlp(text)

    # 1. Keyword Extraction
    # Find the most common words that are not stopwords or punctuation
    stopwords = list(STOP_WORDS)
    pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB']
    keywords = []
    for token in doc:
        if token.text.lower() in stopwords or token.text in punctuation:
            continue
        if token.pos_ in pos_tag:
            keywords.append(token.text)

    freq_word = Counter(keywords)
    top_keywords = [word for word, _ in freq_word.most_common(num_keywords)]

    # 2. Text Summarization
    # Score sentences based on the presence of top keywords
    sentence_scores = {}
    for sent in doc.sents:
        for word in sent:
            if word.text.lower() in top_keywords:
                if sent in sentence_scores:
                    sentence_scores[sent] += 1
                else:
                    sentence_scores[sent] = 1

    # Get the top N sentences for the summary
    summarized_sentences = nlargest(num_sentences, sentence_scores, key=sentence_scores.get)
    summary_text = ' '.join([sent.text.strip() for sent in summarized_sentences])

    # 3. Named Entity Recognition
    # Extract named entities (like people, places, organizations)
    entities = list(set([(ent.text, ent.label_) for ent in doc.ents]))

    # 4. Create the Memory Map Graph using NetworkX
    G = nx.Graph()

    # Add the summary as the central node
    # Wrapping text for better visualization is complex in Matplotlib, so we keep it short.
    G.add_node("Summary", label="Central Idea", color='skyblue', size=3000)

    # Add keyword nodes and connect them to the summary
    for keyword in top_keywords:
        G.add_node(keyword, label=keyword, color='lightgreen', size=1500)
        G.add_edge("Summary", keyword)

    # Add entity nodes and connect them to relevant keywords
    for entity, label in entities:
        if entity not in G:
            G.add_node(entity, label=f"{entity}\n({label})", color='salmon', size=1000)
            for keyword in top_keywords:
                if keyword.lower() in entity.lower() or entity.lower() in keyword.lower():
                    G.add_edge(keyword, entity)

    # 5. Visualize the Graph with Matplotlib
    plt.figure(figsize=(18, 12), dpi=100)
    pos = nx.spring_layout(G, k=1.5, iterations=50, seed=42) # Use a seed for consistent layouts
    
    node_colors = [node[1]['color'] for node in G.nodes(data=True)]
    node_sizes = [node[1]['size'] for node in G.nodes(data=True)]
    labels = {node: data['label'] for node, data in G.nodes(data=True)}

    nx.draw(G, pos, labels=labels, with_labels=True, node_color=node_colors, node_size=node_sizes, 
            font_size=10, font_weight='bold', edge_color='#cccccc', width=1.5)
    
    plt.title("Memory Map", fontsize=20)
    plt.margins(0.1)
    plt.show()

if __name__ == '__main__':
    # --- Example Usage ---
    # Create a file named 'your_text_file.txt' and paste your book chapter or article into it.
    # Then, run this script.
    file_path = 'your_text_file.txt'
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            input_text = file.read()
        print(f"Successfully read '{file_path}'. Generating memory map...")
        generate_memory_map(input_text)
    except FileNotFoundError:
        print(f"Warning: '{file_path}' not found.")
        print("Using a default example text to demonstrate functionality.\n")
        # Example text if the file is not found
        dummy_text = """
        Artificial intelligence (AI) is intelligence demonstrated by machines,
        in contrast to the natural intelligence displayed by humans and animals.
        Leading AI textbooks define the field as the study of "intelligent agents":
        any device that perceives its environment and takes actions that maximize
        its chance of successfully achieving its goals. The term "artificial intelligence"
        had previously been used to describe machines that mimic and display "human"
        cognitive skills that are associated with the human mind, such as "learning"
        and "problem-solving". This definition has since been rejected by major AI
        researchers who now describe AI in terms of rationality and acting rationally,
        which does not limit AI to human-like cognition. The Turing test, developed
        by Alan Turing in 1950, is a test of a machine's ability to exhibit intelligent
        behavior equivalent to, or indistinguishable from, that of a human.
        """
        generate_memory_map(dummy_text)
